
	
	
	 For example, you might want two subshaders, one of higher quality for PC/Desktop and one of lower quality but faster for mobile.
	Here, we're saying we have a vertex function called "vertexFunction", and a fragment function called "fragmentFunction"".
	_Color
	UnityCG.cginc
	COLOR
	https://github.com/TwoTailsGames/Unity-Built-in-Shaders/blob/master/CGIncludes/UnityCG.cginc
	fixed4 color : COLOR;
	fcolor
	        // create new colors array where the colors will be created.          Color[] colors = new Color[vertices.Length];            for (int i = 0; i < vertices.Length; i++)              colors[i] = Color.Lerp(Color.red, Color.green, vertices[i].y);
	processedVertices
	processedVertices.ToArray()
	processedVertices
	Color.green
	processedVertices[i].y
	Color.green
	 List<Vector3>
	Count
	processedVertices[i].y
	

	
	color stream, in general, is accumulated to the voxel to scan  color representation in a similar manner that captures depth
	there is an inevitable tradeoff between  spatial resolution and time performance
	asynchronization between the depth and  color frames
	They lead to inaccurate  estimation of imperfect geometry, color camera pose, and  the mismatch between the geometry and color images
	mitigated
	These challenges could be mitigated by applying a texture mapping method that includes global/local warping of  texture to geometry
	https://dl.acm.org/doi/pdf/10.1145/566654.566590
	http://www.kunzhou.net/publications/isochart.pdf
	http://qianyi.info/scenedata.html
	http://vladlen.info/papers/color-mapping.pdf





	the state-of-the-art models tend to be exceptionally data-hungry
	Large labeled training datasets, expensive and tedious to produce, are required to optimize millions of parameters in deep network models
	the available datasets are quickly becoming outdated in terms of size and density.
	amplify human effort through a partially automated labeling scheme,
	leveraging deep learning with humans in the loop
	We experiment with training popular convolutional networks and find that they achieve substantial performance gains when trained on this dataset.
	
	
	properties of a geometric surface
	heavily used in many areas
	shadings and other visual effects.
	the vector perpendicular to the surface 
	explaining what goes on behind the scenes.
	a k-d tree (short for k-dimensional tree) is a space-partitioning data structure
	The k-d tree is a binary tree in which every leaf node is a k-dimensional point
	k-dimensional
	implicitly generating a splitting hyperplane that divides the space into two parts, known as half-spaces
	dimensional 
	you’re a long time veteran
	comprehensive list of tutorials for PCL
	object detection & reconstruction,
	Transforming, filtering, and registering 3D point clouds
	Segmenting 3D point clouds into clusters and fitting them to geometric shapes
	Reading and visualizing the data
	visualization of vehicle-based point cloud data.
	outlier and noise removal mechanisms
	certain datasets present a large number of shadow points.
	outliers can be filtered by performing a statistical analysis
	trimming those which do not meet a certain criteria. 
	considered as outliers and trimmed from the dataset.
	walk you through the components of your PCL installation, 
	noise removal
	This complicates the estimation of local point cloud 3D features
	assuming that the resulting distribution is Gaussian with a mean and a standard deviation
	all points whose mean distances are outside an interval defined by the global distances mean and standard deviation can be considered as outliers and trimmed from the dataset.
	describe geometrical patterns
	based on the information available around the point.
	underlying surface’s estimated curvature
	local features
	split into smaller chunks using spatial decomposition techniques
	spatial decomposition techniques
	Unarguably
	eigendecomposition
	eigendecomposition (i.e., compute the eigenvectors and eigenvalues) of the k-neighborhood point surface patch
	the eigenvector corresponding to the smallest eigenvalue will approximate the surface normal n at point p
	the surface curvature change will be estimated from the eigenvalues as
	A LAS (LiDAR Aerial Survey) is an open and binary file format which stores LiDAR point cloud data and a point classification system
	its latest Version is LAS 1.4.
	apb_foyer_sampled_seg_pc
	Detection of semantic primitives using  RANSAC and SVM,
	live-view
	 RANSAC  is used to estimate the presence of geometric primitives
	a student of mine asked the standard solution to the exercises, I thought It is not allowed?
	mobile handheld devic
	opens new ways to  interact with it
	geometric primitives
	structural modeling
	Despite a high  computational effort, a meshed surface usually has no semantic  meaning
	our everyday environment largely consists of  very few geometric primitives, mostly planes, boxes, cylinders 
	prior knowledge
	automatic highlighting of object in the environment  become feasible.
	Semantic modeling
	tedious
	In the proposed method,
	一台手机可以连接多台蓝牙设备？
	蓝牙模块通常一般开放的信道也就只能支持到7个左右的并发，也就是说智能手机、平板电脑或者PC通常也就只能同7台蓝牙设备并发连接使用
	蓝牙4.0后，协议本身是允许更多的设备连接使用，但每个协议栈主机分配给协议栈的资源，产品官方其实在介绍蓝牙多连功能时，通常也会公布一个保守的链接数量
	而目前蓝牙已经升级到了5.0，有没有必要购买模块DIY一步升级到位呢？
	 a set  of binary support vector machines (SVM),
	to determine the quality  of the fit.
	primitive label
	forwarded to the next frame
	ill-fitting primitive
	which  we found to be integral parts of everyday environments.
	has been investigated in various contexts
	robot grasping, collision detection
	Hough transforms
	contextual relations.
	investigating their contextual relations
	real-time  scene segmentation
	semantic segmentation of 3D data use convolutional deep belief  networks
	conditional random fields
	use concrete object classes and require a large amount of data for  training.
	a generalized formulation for  objects consisting of geometric primitives is still missing
	 simultaeneous localization and mapping  (SLAM) provides a real-time alternative to offline acquisition of  3D point models.
	simultaeneous localization and mapping  (SLAM)
	segmentation-fitting-refinement pipeline
	applied over multiple frames to refine detected primitives
	make use of ML to decide whether a shape has to be discarded or kept  at runtime
	probabilistic  graphical models 
	closes a gap in research,
	particularly useful in an AR context
	collectively refer to the 3D point cloud, the  related RGB image and the camera pose as a frame
	not an intrinsic restriction of the employed algorithms
	 the user expects quick system response.
	The scenarios are static,  due to the nature of the sensors
	医学影像涉及患者隐私，对算法容错率很低
	在一些比较容易的任务上能达到和医生差不多的水平，在稍微复杂一些的问题上与医生还有很大差距
	既要有一定的医学背景知识，也一定要有计算机编程的能力
	平时不仅要数理化全能，还需要良好的绘画功底，图为胸部某一断层图。
	Poisson reconstruction的目的是生成watertight的且可以保有表面细节的重建方法
	关键在于indicator function
	在表面外为1，在表面内为0.
	只有在接近物体表面的附近才有会有梯度向量，其余位置均为0向量。
	泛函，将曲面外的点映射为00，将曲面内的点映射为11
	全局求解的方法，一次性考虑所有的点。
	此时所得到的表面附近梯度就正好等于了论文中所阐述的inner surface normal，也就是朝向表面内的法向量，-n
	指示函数来找到等值面然后通过marching cube方法
	marching
	Efficient rendering of photo-realistic virtual worlds is a long standing effort of computer graphics.
	photo-realistic computer graphics more widely accessible. 
	 namely deep generative models
	combines generative machine learning techniques with physical knowledge from computer  graphics
	robust tracking
	noisy and/or  oversmoothed
	or has holes due to occlusion
	this makes it nearly  impossible to re-synthesize photo-realistic images
	but tracking dri? and insu乧ient geometric  resolution leads to blur
	Textures are an alternative that tackles the  problem of missing spatial resolution
	here, the geometry and color  resolutions are decoupled
	decoupled
	 the standard graphics pipeline is used to render a view-dependent screen-space feature map
	n converted to photo-realistic imagery based on a Deferred Neural Renderer
	o ?nd the best renderer and texture map
	Surface light ?elds store  the direction-dependent radiance of every point on the surface
	utilize a very coarse geometry  proxy and ?ll in the missing content based on high-resolution 2D  textures 
	Huang et al. 2017
	Image-based rendering (IBR) pushes  this to the limit
	However,  many IBR approaches su?er from ghosting artifacts and problems  at the occlusion boundaries
	 changes the standard rendering  pipeline to address the shortcomings of imperfect 3D surface geometry for rendering photo-realistic imagery
	neural textures
	encode the  appearance of an object in a normalized texture space.
	light-?eld rendering
	able to handle scenes  with complex non-Lambertian surface properties
	Lumitexels/Lumispheres
	Our neural textures can be seen as a learned  analog to these lumitexels
	instead of hand-cra?ed features
	?nd optimal features that can  be interpreted by a neural network such that the original images  are best reproduced
	?e used encoder-decoder network structure  that estimates per-vertex colors is specially designed for the  surface light ?eld use case and learns to ?ll missing sample data  across vertices. 
	 encoder-decoder
	In contrast, the Deep Surface Light Fields approach  needs high quality reconstructions
	‘slight misalignment  can lead to strong artifacts such as ghosting and blurring
	synthesize arti?cial 2D imagery
	generative adversarial networks (GANs) [Goodfellow et al.  2014]
	impressive results
	reenactment synthesis pipeline
	expression transfer
	we generate an altered uv map of  the target actor matching
	enable photo-realistic image  synthesis based on imperfect commodity 3D reconstructions.
	Neural Textures are a new  graphics primitive that can have arbitrary dimension and store  a high-dimensional learned feature vector per texel
	Deferred Neural Rendering:  Image Synthesis using Neural Textures
	trained Deferred Neural Renderer, the sampled image space feature  map is then interpreted.
	https://github.com/luanfujun/deep-photo-styletransfer
	Typically, they contain appearance information,  such as the albedo of an object, but they can also store custom  a?ributes
	such as high-frequency geometric detail in the form of  normal or displacement map
	interpreted by programmed shader programs.
	Neural Textures are an extension of traditional texture  maps
	they store learned high-dimensional feature maps capable of storing signi?cantly more information
	new deferred neural rendering pipeline
	Both mini?cation and magni?cation might appear at the  same time for di?erent parts of the scene. I
	Mipmaps are used to tackle this challenge. Inspired by  classical Mipmaps, we propose to employ Neural Texture Hierarchies  with K levels.
	We train our neural rendering approach end-to-end using stochastic  gradient descent.
	https://math.stackexchange.com/questions/681376/texture-mapping-from-a-camera-image-knowing-the-camera-pose
	MeshLab can manipulate the vertex and face colors using a series of photoshop-like filters (gamma, saturation, brightness, contrast, levels, smoothing, sharpening).
	painting interface for vertex colors. Scalar values
	be mapped on vertex/face color
	have a visual representation of that value.
	Color information may be as important as geometry
	MeshLab contains a pipeline for the alignment and projection of color information (from a set of uncalibrated images) onto a 3D model
	many more geometrical and topological singularities
	geometrical detail and texture mapping, or to selectively reduce the number of points in a pointcloud. 
	In other cases, the user may want to increase the number of triangles (or points): MeshLab also provides different subdivision schemes
	remeshing
	increase geometric complexity of 3D models
	optimize point distribution and triangulation quality.
	Different geometric information (like curvature, geodesic distance, or local vertex density) may be calculated on meshes and 3D models using automatic filters.
	Render > show vertex Normals 
	Dear Matthew
	Krishnan
	Dear Matthew, Krishnan?,         12 is suitable for me.         Best regards,     Zhongyuan 
	Dear Matthew, Krishnan?, 12 is suitable for me. Best regards, Zhongyuan
	acquilab 1_nml
	                      https://github.com/LiangliangNan/PolyFit 
	              https://lgg.epfl.ch/publications/2014/reconstar/paper.pdf              Nico papers:                   https://tud.qucosa.de/api/qucosa%3A32056/attachment/ATT-0/?L=1              https://arxiv.org/pdf/1703.04079.pdf              https://3d.bk.tudelft.nl/liangliang/publications/2009/BATR_2009.pdf              https://www.mdpi.com/2220-9964/9/5/330/pdf              RandLANet: Efficient Semantic Segmentation of Large-Scale PointClouds              Pytorch: Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction              https://tud.qucosa.de/search/?no_cache=1&L=1&tx_dpf_frontendsearch%5Baction%5D=search&tx_dpf_frontendsearch%5Bcontroller%5D=SearchFE              stru: 
	Voronoi based
	[K?nig13]
	bundlefusion
	                  https://github.com/alicevision/meshroom
	Victor
	active participation in a direct and practical way.
	 photogrammetry software
	geo-referenced maps
	Texture Reprojection
	You can project a texture created on a high-detail model onto a highly simplified model for considerably shorter time(compared to 
	get the sharpest texture possible. 
	exture a strongly simplified or a re-topologized model.
	A model after simplification loses its roughness and thus becomes much smoother,mainly in any ragged areas
	This is due to large differences between the two surfaces.
	"Nearest sampling" is fast although might result inaliasing artifacts unless sufficient "Supersampling" is in use
	"Trilinear sampling" (recommended) eliminates any aliasing artifacts
	which is fine for denser objects
	 and which makes the model smaller in size, compared to a textured model
	Simply speaking, texturing creates a small image for each triangle of the model
	This method is therefore more realistic than coloring. 
	Reality Capture
	Create a MeshDecimate node, connect it, adjust parameters and start computation
	Double-Click on a node to visualize it in the 3D viewer.
	Step 6: Retexturing after Retopology
	re-texture this geometry.
	External retopology and custom UVs 
	outside Meshroom (e.g: retopology / unwrap)
	https://www.youtube.com/watch?v=-CwdugODkmQ
	I've seen this video where they were using Laser in combination with photo scanning, and they've got really good results.
	But it's far from being ready for end-users.
	https://github.com/alicevision/meshroom/wiki/Texturing-after-external-re-topology
	https://github.com/alicevision/meshroom/issues/764
	https://github.com/alicevision/meshroom/wiki/Texturing-after-external-re-topology
	https://www.danielgm.net/cc/forum/viewtopic.php?f=17&t=1680&sid=c9b39d0d95f556e7e88e1e610719537e
	internationalized 
	multi-platform (GNU Linux, Windows and MacOS) and provides several tools:
	https://github.com/miykael/3dprintyourbrain
