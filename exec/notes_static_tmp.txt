
	
	
	 For example, you might want two subshaders, one of higher quality for PC/Desktop and one of lower quality but faster for mobile.
	Here, we're saying we have a vertex function called "vertexFunction", and a fragment function called "fragmentFunction"".
	_Color
	UnityCG.cginc
	COLOR
	https://github.com/TwoTailsGames/Unity-Built-in-Shaders/blob/master/CGIncludes/UnityCG.cginc
	fixed4 color : COLOR;
	fcolor
	        // create new colors array where the colors will be created.          Color[] colors = new Color[vertices.Length];            for (int i = 0; i < vertices.Length; i++)              colors[i] = Color.Lerp(Color.red, Color.green, vertices[i].y);
	processedVertices
	processedVertices.ToArray()
	processedVertices
	Color.green
	processedVertices[i].y
	Color.green
	 List<Vector3>
	Count
	processedVertices[i].y
	

	
	color stream, in general, is accumulated to the voxel to scan  color representation in a similar manner that captures depth
	there is an inevitable tradeoff between  spatial resolution and time performance
	asynchronization between the depth and  color frames
	They lead to inaccurate  estimation of imperfect geometry, color camera pose, and  the mismatch between the geometry and color images
	mitigated
	These challenges could be mitigated by applying a texture mapping method that includes global/local warping of  texture to geometry
	https://dl.acm.org/doi/pdf/10.1145/566654.566590
	http://www.kunzhou.net/publications/isochart.pdf
	http://qianyi.info/scenedata.html
	http://vladlen.info/papers/color-mapping.pdf





	the state-of-the-art models tend to be exceptionally data-hungry
	Large labeled training datasets, expensive and tedious to produce, are required to optimize millions of parameters in deep network models
	the available datasets are quickly becoming outdated in terms of size and density.
	amplify human effort through a partially automated labeling scheme,
	leveraging deep learning with humans in the loop
	We experiment with training popular convolutional networks and find that they achieve substantial performance gains when trained on this dataset.
	
	
	properties of a geometric surface
	heavily used in many areas
	shadings and other visual effects.
	the vector perpendicular to the surface 
	explaining what goes on behind the scenes.
	a k-d tree (short for k-dimensional tree) is a space-partitioning data structure
	The k-d tree is a binary tree in which every leaf node is a k-dimensional point
	k-dimensional
	implicitly generating a splitting hyperplane that divides the space into two parts, known as half-spaces
	dimensional 
	you’re a long time veteran
	comprehensive list of tutorials for PCL
	object detection & reconstruction,
	Transforming, filtering, and registering 3D point clouds
	Segmenting 3D point clouds into clusters and fitting them to geometric shapes
	Reading and visualizing the data
	visualization of vehicle-based point cloud data.
	outlier and noise removal mechanisms
	certain datasets present a large number of shadow points.
	outliers can be filtered by performing a statistical analysis
	trimming those which do not meet a certain criteria. 
	considered as outliers and trimmed from the dataset.
	walk you through the components of your PCL installation, 
	noise removal
	This complicates the estimation of local point cloud 3D features
	assuming that the resulting distribution is Gaussian with a mean and a standard deviation
	all points whose mean distances are outside an interval defined by the global distances mean and standard deviation can be considered as outliers and trimmed from the dataset.
	describe geometrical patterns
	based on the information available around the point.
	underlying surface’s estimated curvature
	local features
	split into smaller chunks using spatial decomposition techniques
	spatial decomposition techniques
	Unarguably
	eigendecomposition
	eigendecomposition (i.e., compute the eigenvectors and eigenvalues) of the k-neighborhood point surface patch
	the eigenvector corresponding to the smallest eigenvalue will approximate the surface normal n at point p
	the surface curvature change will be estimated from the eigenvalues as
	A LAS (LiDAR Aerial Survey) is an open and binary file format which stores LiDAR point cloud data and a point classification system
	its latest Version is LAS 1.4.
	apb_foyer_sampled_seg_pc
	Detection of semantic primitives using  RANSAC and SVM,
	live-view
	 RANSAC  is used to estimate the presence of geometric primitives
	a student of mine asked the standard solution to the exercises, I thought It is not allowed?
	mobile handheld devic
	opens new ways to  interact with it
	geometric primitives
	structural modeling
	Despite a high  computational effort, a meshed surface usually has no semantic  meaning
	our everyday environment largely consists of  very few geometric primitives, mostly planes, boxes, cylinders 
	prior knowledge
	automatic highlighting of object in the environment  become feasible.
	Semantic modeling
	tedious
	In the proposed method,
	一台手机可以连接多台蓝牙设备？
	蓝牙模块通常一般开放的信道也就只能支持到7个左右的并发，也就是说智能手机、平板电脑或者PC通常也就只能同7台蓝牙设备并发连接使用
	蓝牙4.0后，协议本身是允许更多的设备连接使用，但每个协议栈主机分配给协议栈的资源，产品官方其实在介绍蓝牙多连功能时，通常也会公布一个保守的链接数量
	而目前蓝牙已经升级到了5.0，有没有必要购买模块DIY一步升级到位呢？
	 a set  of binary support vector machines (SVM),
	to determine the quality  of the fit.
	primitive label
	forwarded to the next frame
	ill-fitting primitive
	which  we found to be integral parts of everyday environments.
	has been investigated in various contexts
	robot grasping, collision detection
	Hough transforms
	contextual relations.
	investigating their contextual relations
	real-time  scene segmentation
	semantic segmentation of 3D data use convolutional deep belief  networks
	conditional random fields
	use concrete object classes and require a large amount of data for  training.
	a generalized formulation for  objects consisting of geometric primitives is still missing
	 simultaeneous localization and mapping  (SLAM) provides a real-time alternative to offline acquisition of  3D point models.
	simultaeneous localization and mapping  (SLAM)
	segmentation-fitting-refinement pipeline
	applied over multiple frames to refine detected primitives
	make use of ML to decide whether a shape has to be discarded or kept  at runtime
	probabilistic  graphical models 
	closes a gap in research,
	particularly useful in an AR context
	collectively refer to the 3D point cloud, the  related RGB image and the camera pose as a frame
	not an intrinsic restriction of the employed algorithms
	 the user expects quick system response.
	The scenarios are static,  due to the nature of the sensors
	医学影像涉及患者隐私，对算法容错率很低
	在一些比较容易的任务上能达到和医生差不多的水平，在稍微复杂一些的问题上与医生还有很大差距
	既要有一定的医学背景知识，也一定要有计算机编程的能力
	平时不仅要数理化全能，还需要良好的绘画功底，图为胸部某一断层图。
	Poisson reconstruction的目的是生成watertight的且可以保有表面细节的重建方法
	关键在于indicator function
	在表面外为1，在表面内为0.
	只有在接近物体表面的附近才有会有梯度向量，其余位置均为0向量。
	泛函，将曲面外的点映射为00，将曲面内的点映射为11
	全局求解的方法，一次性考虑所有的点。
	此时所得到的表面附近梯度就正好等于了论文中所阐述的inner surface normal，也就是朝向表面内的法向量，-n
	指示函数来找到等值面然后通过marching cube方法
	marching
	Efficient rendering of photo-realistic virtual worlds is a long standing effort of computer graphics.
	photo-realistic computer graphics more widely accessible. 
	 namely deep generative models
	combines generative machine learning techniques with physical knowledge from computer  graphics
	robust tracking
	noisy and/or  oversmoothed
	or has holes due to occlusion
	this makes it nearly  impossible to re-synthesize photo-realistic images
	but tracking dri? and insu乧ient geometric  resolution leads to blur
	Textures are an alternative that tackles the  problem of missing spatial resolution
	here, the geometry and color  resolutions are decoupled
	decoupled
	 the standard graphics pipeline is used to render a view-dependent screen-space feature map
	n converted to photo-realistic imagery based on a Deferred Neural Renderer
	o ?nd the best renderer and texture map
	Surface light ?elds store  the direction-dependent radiance of every point on the surface
	utilize a very coarse geometry  proxy and ?ll in the missing content based on high-resolution 2D  textures 
	Huang et al. 2017
	Image-based rendering (IBR) pushes  this to the limit
	However,  many IBR approaches su?er from ghosting artifacts and problems  at the occlusion boundaries
	 changes the standard rendering  pipeline to address the shortcomings of imperfect 3D surface geometry for rendering photo-realistic imagery
	neural textures
	encode the  appearance of an object in a normalized texture space.
	light-?eld rendering
	able to handle scenes  with complex non-Lambertian surface properties
	Lumitexels/Lumispheres
	Our neural textures can be seen as a learned  analog to these lumitexels
	instead of hand-cra?ed features
	?nd optimal features that can  be interpreted by a neural network such that the original images  are best reproduced
	?e used encoder-decoder network structure  that estimates per-vertex colors is specially designed for the  surface light ?eld use case and learns to ?ll missing sample data  across vertices. 
	 encoder-decoder
	In contrast, the Deep Surface Light Fields approach  needs high quality reconstructions
	‘slight misalignment  can lead to strong artifacts such as ghosting and blurring
	synthesize arti?cial 2D imagery
	generative adversarial networks (GANs) [Goodfellow et al.  2014]
	impressive results
	reenactment synthesis pipeline
	expression transfer
	we generate an altered uv map of  the target actor matching
	enable photo-realistic image  synthesis based on imperfect commodity 3D reconstructions.
	Neural Textures are a new  graphics primitive that can have arbitrary dimension and store  a high-dimensional learned feature vector per texel
	Deferred Neural Rendering:  Image Synthesis using Neural Textures
	trained Deferred Neural Renderer, the sampled image space feature  map is then interpreted.
	https://github.com/luanfujun/deep-photo-styletransfer
	Typically, they contain appearance information,  such as the albedo of an object, but they can also store custom  a?ributes
	such as high-frequency geometric detail in the form of  normal or displacement map
	interpreted by programmed shader programs.
	Neural Textures are an extension of traditional texture  maps
	they store learned high-dimensional feature maps capable of storing signi?cantly more information
	new deferred neural rendering pipeline
	Both mini?cation and magni?cation might appear at the  same time for di?erent parts of the scene. I
	Mipmaps are used to tackle this challenge. Inspired by  classical Mipmaps, we propose to employ Neural Texture Hierarchies  with K levels.
	We train our neural rendering approach end-to-end using stochastic  gradient descent.
	https://math.stackexchange.com/questions/681376/texture-mapping-from-a-camera-image-knowing-the-camera-pose
	MeshLab can manipulate the vertex and face colors using a series of photoshop-like filters (gamma, saturation, brightness, contrast, levels, smoothing, sharpening).
	painting interface for vertex colors. Scalar values
	be mapped on vertex/face color
	have a visual representation of that value.
	Color information may be as important as geometry
	MeshLab contains a pipeline for the alignment and projection of color information (from a set of uncalibrated images) onto a 3D model
	many more geometrical and topological singularities
	geometrical detail and texture mapping, or to selectively reduce the number of points in a pointcloud. 
	In other cases, the user may want to increase the number of triangles (or points): MeshLab also provides different subdivision schemes
	remeshing
	increase geometric complexity of 3D models
	optimize point distribution and triangulation quality.
	Different geometric information (like curvature, geodesic distance, or local vertex density) may be calculated on meshes and 3D models using automatic filters.
	Render > show vertex Normals 
	Dear Matthew
	Krishnan
	Dear Matthew, Krishnan?,         12 is suitable for me.         Best regards,     Zhongyuan 
	Dear Matthew, Krishnan?, 12 is suitable for me. Best regards, Zhongyuan
	acquilab 1_nml
	                      https://github.com/LiangliangNan/PolyFit 
	              https://lgg.epfl.ch/publications/2014/reconstar/paper.pdf              Nico papers:                   https://tud.qucosa.de/api/qucosa%3A32056/attachment/ATT-0/?L=1              https://arxiv.org/pdf/1703.04079.pdf              https://3d.bk.tudelft.nl/liangliang/publications/2009/BATR_2009.pdf              https://www.mdpi.com/2220-9964/9/5/330/pdf              RandLANet: Efficient Semantic Segmentation of Large-Scale PointClouds              Pytorch: Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction              https://tud.qucosa.de/search/?no_cache=1&L=1&tx_dpf_frontendsearch%5Baction%5D=search&tx_dpf_frontendsearch%5Bcontroller%5D=SearchFE              stru: 
	Voronoi based
	[K?nig13]
	bundlefusion
	                  https://github.com/alicevision/meshroom
	Victor
	active participation in a direct and practical way.
	 photogrammetry software
	geo-referenced maps

	
	
	
	

		Dense 3D Point Cloud Reconstruction
	Deep Pyramid Network
	https://cg.cs.uni-bonn.de/en/publications/paper-details/schnabel-2007-efficient/
	Efficient RANSAC for Point-Cloud Shape Detection
	https://www.ais.uni-bonn.de/papers/IAS_2012_Holz.pdf
	Fast Range Image Segmentation and Smoothing using  Approximate Surface Reconstruction and Region Growing
	structured overview of the  field
	classifies the existing literature
	the kind of indoor  environments that still pose major challenges.
	https://arxiv.org/list/cs.GR/recent
	https://matthewberger.github.io/papers/reconstar.pdf
	State of the Art in Surface Reconstruction from Point Clouds
	https://doc.cgal.org/latest/Manual/tuto_reconstruction.html
	https://arxiv.org/pdf/2102.05921.pdf
	https://hal.inria.fr/hal-01348404v2/document
	image_dir
	canvas
	A = np.empty([1816, 2464, 3])
	that optimize certain application-dependent characteristics
	https://openaccess.thecvf.com/content_iccv_2015/papers/Ikehata_Structured_Indoor_Modeling_ICCV_2015_paper.pdf
	Structured Indoor Modeling
	a dataset of high quality reconstructions of a variety of indoor spaces.
	Each reconstruction has clean dense geometry, high resolution and high dynamic range textures
	glass and mirror surface information
	dense geometry
	ReplicaRenderer.
	https://github.com/facebookresearch/Replica-Dataset.git
	grbgetkey 95a24c8c-7244-11eb-be27-0a7c4f30bdbe
	https://arxiv.org/pdf/1906.05797.pdf
	18 highly  photo-realistic 3D indoor scene reconstructions
	egocentric computer vision
	embodied agents (virtual robots) performing navigation
	natively used with AI Habitat [24] for  training and testing embodied agents
	full fidelity
	Digitizing real environments has  many future use cases
	 virtual telepresence
	a smaller domain gap between simulation and  reality.
	Compared to other 3D datasets such as Matterport 3D [6]  and ScanNet [8], Replica achieves significantly higher levels  of realism
	instance annotation of each primitive
	a large range of object instances from 88  semantic classes
	 a large range of object instances from 88  semantic classes to facilitate interesting machine learning  tasks
	Geometry and texturing artifacts are noticeable  in both Matterport 3D and ScanNet
	https://arxiv.org/pdf/1906.05797.pdf
	(1) human-generated synthetic scenes based on  CAD models and (2) reconstructions of real environments.  They vary in semantic and visual realism
	semantically overly simplistic
	InteriorNet
	interiornetdataset.github.io
	https://interiornet.org/
	InteriorNet: Mega-scale Multi-sensor Photo-realistic  Indoor Scenes Dataset
	We also thank the Kujiale artists and other professionals for their great efforts into editing and labelling millions of models and scenes
	https://interiornet.org/items/interiornet_paper.pdf
	Felsenszwalb segmentation
	 renderable reflectors
	surfaces  were not sufficiently captured during scanning
	ensure the highest quality 3D meshes
	in our custom built software tool by specifying the boundary  of the reflector on the mesh.
	forest data structure which we call a segmentation forest
	segmentation forest data structure
	Rendering at different levels  of the forest leads to different segmentations of the scene.
	The  scenes were selected with an eye towards semantic variety
	as well as their scale
	 touch up.
	facilitate easier human interpretation for manual touch up.
	HDR textures are obtained by cycling the exposure times  of the RGB texture camera
	fusing the measured radiance per texel into 16 bit  floating point RGB values
	Mudbox 
	https://arxiv.org/pdf/1906.05797.pdf
	that is pretty impressive and exactly similar to our goal
	Instant Meshes
	https://github.com/wjakob/instant-meshes
	https://igl.ethz.ch/projects/instant-meshes/instant-meshes-SA-2015-jakob-et-al.pdf
	Instant Field-Aligned Meshes
	                  [2015]  Instant Field-Aligned Meshes                      https://igl.ethz.ch/projects/instant-meshes/instant-meshes-SA-2015-jakob-et-al.pdf
	The standard workflow is to solve for an orientation field (first blue button) and a position field (second blue button) in sequence
	descriptive message when hovering the mouse cursor above for a second.
	OnlineSurfaceReconstruction
	extract NARF Features
	interest point detection
	In this work we focus on single range scans, as obtained  with 3D laser range finders or stereo cameras
	cloud
	    pcl::PointCloud<pcl::PointXYZ>::Ptr cloud(new pcl::PointCloud<pcl::PointXYZ>);      if (pcl::io::loadPLYFile<pcl::PointXYZ>(          "E:/Dataset_2021/PointClouds_BLK360/2073-office-mm_08_02_2021_ns4/best-pointcloud-CC-nml.ply", *cloud) == -1)      {          std::cout << "Cloud reading failed." << std::endl;          return (-1);      }
	    pcl::visualization::CloudViewer viewer("Cluster viewer");      viewer.showCloud(cloud);      while (!viewer.wasStopped())      {      }
	find a transformation that minimizes the distance
	This process is repeated, since correspondence search is affected by the relative position and orientation of the data sets
	Once the alignment errors fall below a given threshold, the registration is said to be complete.
	The registration library implements a plethora of point cloud registration algorithms for both organized and unorganized (general purpose) datasets.
	For instance, PCL contains a set of powerful algorithms that allow the estimation of multiple sets of correspondences, as well as methods for rejecting bad correspondences, and estimating transformations in a robust manner.
	estimating transformations in a robust manner.
	segmenting a point cloud into distinct clusters.
	spatially isolated regions.
	break the cloud down into its constituent parts
	SAmple Consensus (SAC) methods like RANSAC and models like planes and cylinders
	detect specific models and their parameters in point clouds.
	Some of the models implemented in this library include: lines, planes, cylinders, and spheres. Plane fitting is often applied to the task of detecting common indoor surfaces
	Other models can be used to detect and segment objects with common geometric structures (e.g., fitting a cylinder model to a mug).
	The surface library deals with reconstructing the original surfaces from 3D scans
	Smoothing and resampling can be important if the cloud is noisy
	a very fast triangulation of the original points, and a slower meshing that does smoothing and hole filling as well.
	The range_image library contains two classes for representing and working with range images
	Range images are a common 3D representation and are often generated by stereo or time-of-flight cameras
	With knowledge of the camera’s intrinsic calibration parameters, a range image can be converted into a point cloud.
	The search library provides methods for searching for nearest neighbors using different data structures, including:  KdTree  Octree  brute force  specialized search for organized datasets
	specialized search for organized datasets
	simplify AR/VR software development
	https://github.com/KhronosGroup/OpenXR-SDK.git
	shaders in an intermediate representation called SPIR-V.
	This makes it possible to use different shader languages by compiling them to that bytecode format. 
	 The primary shader language used here is GLSL but thanks to an external contribution you'll also find HLSL shader sources.
	https://github.com/nvpro-samples/vk_raytracing_tutorial_KHR
	https://github.com/SaschaWillems/Vulkan
	VULKAN_EXAMPLE_MAIN()
